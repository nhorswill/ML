{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from math import floor, ceil\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess data\n",
    "(x_img_train,y_label_train),(x_img_test,y_label_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x\n",
    "x_train = normalize(x_img_train).reshape(50000,32*32*3)\n",
    "x_test = normalize(x_img_test).reshape(10000,32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhors\\.conda\\envs\\tf_cpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\nhors\\.conda\\envs\\tf_cpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## One hot encoding of labels\n",
    "\n",
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "encode=OneHotEncoder(dtype=np.float32,sparse=False)\n",
    "\n",
    "y_train=encode.fit_transform(y_label_train)\n",
    "y_test=encode.fit_transform(y_label_test)\n",
    "\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "\n",
    "sns.set(style='ticks', palette='Spectral', font_scale=1.5)\n",
    "\n",
    "material_palette = [\"#4CAF50\", \"#2196F3\", \"#9E9E9E\", \"#FF9800\", \"#607D8B\", \"#9C27B0\"]\n",
    "sns.set_palette(material_palette)\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "plt.xkcd();\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "tf.set_random_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrapper function\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases, keep_prob):\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "## NN shape\n",
    "\n",
    "n_hidden = 1024\n",
    "n_input = x_train.shape[1]\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "## Hyperparams\n",
    "\n",
    "training_epochs = 25\n",
    "display_step = 1\n",
    "batch_size = 32\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining loss function\n",
    "predictions = multilayer_perceptron(x, weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resampling indices\n",
    "x_indices = np.random.choice(50000,128000)\n",
    "type(x_train)\n",
    "total_batch = np.concatenate((np.linspace(32,32*100,100),np.linspace(3264,3264+64*149,150),np.linspace(12800+128,12800+128+128*199,200)))\n",
    "total_batch = np.concatenate((total_batch,np.linspace(38400+256,38400+256+256*249,250),np.linspace(102400+512,102400+512+512*49,50)))\n",
    "total_batch = np.concatenate(([0],total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19294, 49790, 10774, ..., 17842, 25691, 31388])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## smush x_train and y_train, random sample x128000, then split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 2331.063377546\n",
      "Epoch: 0002 cost= 970.197704828\n",
      "Epoch: 0003 cost= 724.890203388\n",
      "Epoch: 0004 cost= 616.160504150\n",
      "Epoch: 0005 cost= 558.395989487\n",
      "Epoch: 0006 cost= 535.228945703\n",
      "Epoch: 0007 cost= 513.560534290\n",
      "Epoch: 0008 cost= 495.105505874\n",
      "Epoch: 0009 cost= 476.536110160\n",
      "Epoch: 0010 cost= 458.960800014\n",
      "Epoch: 0011 cost= 443.534137844\n",
      "Epoch: 0012 cost= 428.707146084\n",
      "Epoch: 0013 cost= 414.534580191\n",
      "Epoch: 0014 cost= 399.612507928\n",
      "Epoch: 0015 cost= 386.153957721\n",
      "Epoch: 0016 cost= 372.469228843\n",
      "Epoch: 0017 cost= 359.563503619\n",
      "Epoch: 0018 cost= 347.105698104\n",
      "Epoch: 0019 cost= 333.920939023\n",
      "Epoch: 0020 cost= 322.826967849\n",
      "Epoch: 0021 cost= 312.093698403\n",
      "Epoch: 0022 cost= 303.386896979\n",
      "Epoch: 0023 cost= 294.557034837\n",
      "Epoch: 0024 cost= 283.372540032\n",
      "Epoch: 0025 cost= 275.534135642\n",
      "Optimization Finished!\n",
      "Accuracy: 0.3583\n",
      "4.506707155704499  minutes\n"
     ]
    }
   ],
   "source": [
    "## backpropagation of NN\n",
    "import time\n",
    "t1=time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        x_batches = np.split(x_train_1, total_batch)\n",
    "        y_batches = np.split(y_train_1, total_batch)\n",
    "        for i in range(total_batch):\n",
    "            batch_y = y_batches[i]\n",
    "            batch_x = x_batches[i]\n",
    "            est, c = sess.run([optimizer, cost], \n",
    "                            feed_dict={\n",
    "                                x: batch_x, \n",
    "                                y: batch_y,\n",
    "                                keep_prob: 0.8\n",
    "                            })\n",
    "            avg_cost += c / total_batch\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    #print (\"Validation Accuracy:\", accuracy.eval({x: x_test, y: y_test}))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: x_test, y: y_test, keep_prob: 1.0}))\n",
    "    \n",
    "t2=time.time()\n",
    "print((t2-t1)/60,\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf_cpu]",
   "language": "python",
   "name": "conda-env-.conda-tf_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
